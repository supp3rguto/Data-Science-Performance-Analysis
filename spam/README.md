# üö´ An√°lise de Dados ‚Äî Spam Detection Dataset

Este notebook apresenta uma an√°lise preditiva e t√©cnicas de **Processamento de Linguagem Natural (NLP)** sobre um conjunto de dados de **Spam**, aplicando **Machine Learning** para classificar textos como "spam" ou "ham" (n√£o-spam).

## üìä Objetivo

Explorar e modelar o conjunto de dados **Spam**, com o objetivo de construir um modelo de classifica√ß√£o capaz de prever com precis√£o se uma nova mensagem de texto √© ou n√£o spam, com base em seu conte√∫do.

## üß∞ Tecnologias Utilizadas

- **Python 3+**
- **Jupyter Notebook**
- **Pandas** ‚Äî manipula√ß√£o e an√°lise de dados
- **NumPy** ‚Äî opera√ß√µes matem√°ticas
- **Matplotlib** e **Seaborn** ‚Äî visualiza√ß√£o dos dados
- **Scikit-learn** ‚Äî modelagem preditiva e processamento de texto
    - `TfidfVectorizer` (para vetoriza√ß√£o de texto)
    - `LabelEncoder` (para a vari√°vel alvo)
    - `DecisionTreeClassifier` (modelo de classifica√ß√£o)
    - `train_test_split`, `cross_val_score`
    - `accuracy_score`, `classification_report`, `confusion_matrix`

## ‚öôÔ∏è Etapas Realizadas

1.  Carregamento e inspe√ß√£o dos dados (`spam.csv`).
2.  Processamento de Texto (NLP): Transforma√ß√£o da coluna `text` em uma matriz num√©rica de *features* usando `TfidfVectorizer`, limitando a 5000 *features* e removendo *stop words*.
3.  Codifica√ß√£o da vari√°vel alvo (`text_type`) de categ√≥rica para num√©rica ('ham' -> 0, 'spam' -> 1) com `LabelEncoder`.
4.  Avalia√ß√£o inicial do modelo `DecisionTreeClassifier` usando valida√ß√£o cruzada (`cross_val_score`) para estimar a performance m√©dia.
5.  Separa√ß√£o dos dados vetorizados em conjuntos de treino e teste.
6.  Treinamento do modelo final de √Årvore de Decis√£o (`random_state=42`).
7.  Avalia√ß√£o detalhada do desempenho do modelo no conjunto de teste, incluindo acur√°cia, *classification report* (precision, recall, f1-score) e uma matriz de confus√£o visualizada.

## üöÄ Resultados e Conclus√µes

O modelo de **√Årvore de Decis√£o**, combinado com a vetoriza√ß√£o **TF-IDF**, mostrou-se eficaz na detec√ß√£o de spam, alcan√ßando uma **acur√°cia de aproximadamente 90,5%** no conjunto de teste.

A valida√ß√£o cruzada inicial j√° apontava uma acur√°cia m√©dia de ~85,6%. O *classification report* final indica um bom equil√≠brio entre *precision* e *recall* para ambas as classes, com o modelo sendo ligeiramente melhor em identificar "ham" (classe 0) do que "spam" (classe 1). A matriz de confus√£o confirma que o modelo classifica corretamente a grande maioria das mensagens.
